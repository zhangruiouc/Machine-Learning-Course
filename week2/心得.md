# 学习与实验
## 多维特征
目前为止，我们探讨了单变量/特征的回归模型，现在我们对房价模型增加更多的特征，例如房间数楼层等，构成一个含有多个变量的模型，模型中的特征为x1到xn的向量。</br>
* n代表特征的数量
* 带上标i的x表示第i个训练实例，是特征矩阵中的第i行，是一个向量（vector）
* 支持多个向量的假设h可以表示为：</br>
* ![image](https://user-images.githubusercontent.com/130215873/233818838-1be1893f-ac40-4d46-be33-fbd57f9d2d66.png)</br>
* 上述的公式中x可以表示为向量，参数也可以表示为一个向量，可以使用numpy中的numpy.dot来方便的表示两个向量的上述内积表示，再加上一个参数即可。
## 多变量的梯度下降
想要研究梯度下降，就必须先构建一个代价函数，在多变量的线性回归中，这个代价函数可以构造为：</br>
![image](https://user-images.githubusercontent.com/130215873/233819015-2970576a-c0c6-49b8-85bd-fcbc9a56b8fd.png)</br>
在多变量的线性回归中，我们的目标同样是找到使得代价函数最小的一系列参数，类似的设置多变量线性回归的批量梯度下降算法为：</br>
这里的参数同样是同时更新的，不能更新完一个参数后带入代价函数再计算另一个参数。按照下图的方式更新所有参数，计算出代价函数的值后不断迭代，最后的期望结果是这个代价函数能收敛。</br>
![image](https://user-images.githubusercontent.com/130215873/233819204-2472363f-bff1-450b-9839-63d5122c2641.png)</br>
## 特征缩放
我们希望再面对多维特征问题时，这些特征都具有相近的尺度，这可以帮助梯度下降算法更快地收敛， 
这里我选取了一个最常见，我认为也是最好的缩放特征值的方法，基于正态分布的特征缩放。 
![image](https://user-images.githubusercontent.com/130215873/233819311-00d1624e-ae17-4b0d-9fa6-8c2d70aef252.png)</br>
特征缩放可以帮助我们把特征值限定在一个合适的范围，这个范围是否合适，需要根据原来特征值范围的大小以及其他特征值的大小来判断。 
## 学习率α的选取
梯度下降算法收敛所需要的迭代次数根据模型的不同而不同，我们不能提前预知，我们可以绘制迭代次数和代价函数的图表来观测算法在何时趋于收敛。 
<img width="151" alt="image" src="https://user-images.githubusercontent.com/130215873/233819357-1f8fa7b3-6c17-4ba6-be8b-bec1c95a7f08.png"></br>
梯度下降算法的每次迭代受到学习率的影响，如果学习率过小，则达到收敛所需的迭代次数会非常高；如果学习率过大，每次迭代可能不会减小代价函数，可能会越过局部最小值导致无法收敛。 
通常可以考虑尝试些学习率： 
> α = 0.01，0.03，0.1，0.3，1...</br>
## 特征与多项式回归
依然以预测房价的问题为例。房子所占地区的长度和宽度都可以作为特征值，同时我们可以把长度和宽度做一个乘法，也就是面积作为一个新的特征值。</br>
![image](https://user-images.githubusercontent.com/130215873/233819596-1358c1c0-25a3-459a-9e78-ef31e7f58bcb.png)</br>
同时，线性回归并不适用于所有数据，有时我们需要曲线来适应我们的数据，比如一个二次方模型：</br>
![image](https://user-images.githubusercontent.com/130215873/233819619-c8203f74-bdd2-46b0-bb52-f839441d1e5f.png)</br>
我们需要先观察数据再决定准备尝试什么样的模型，还可以尝试添加根号的形式：</br>
![image](https://user-images.githubusercontent.com/130215873/233819676-b3ca8d2d-7510-47cd-bc25-56d53146f6f0.png)
如果采用多项式的回归模型，在运行梯度下降算法前，一定要进行特征缩放。 
# 实验
## 特征值缩放和α的选取
如图所示，在面对多特征值的问题时，我们需要做特征值的缩放。</br>
![image](https://user-images.githubusercontent.com/130215873/233820189-71e4ef82-3f48-46c4-ac42-09bd6b6fa5b2.png)</br>
经过特征值缩放，我们达到了两个目的。
* 通过归一化将峰值范围减小
* 将特征值的范围缩小在一个合适的区间，例如图中的从-1到+1
如图所示，缩放后的特征值很好地符合我们的要求。在达到100次迭代后，代价函数的值就趋于收敛，之后包括代价函数的值和各个参数的值也没有发生大的变化。</br>
![image](https://user-images.githubusercontent.com/130215873/233820435-a44d1142-beb1-4819-8b39-b6e93ee084dc.png)
接下来我们在图上标出预测的房价和target，可以发现两者非常地接近。这里展示时用的数据是原始的数据，而非缩放后的。</br>
![image](https://user-images.githubusercontent.com/130215873/233820521-a29a45bd-0be1-4178-94b8-f05b35d0fc1c.png)
## Feature Engineering以及多项式回归
对于如图所示的数据集，可以观察到如果用直线来拟合，效果并不理想。这时，就可以采用**feature engineering**的方法，做y=1+x^2的函数，同时通过多维的梯度下降算法，确定x^2前的参数w和这个函数的常数项b。最后得到的w和b如图所示，拟合的效果也很好。</br>
![image](https://user-images.githubusercontent.com/130215873/233821048-52822a89-9068-4b3d-95da-1d21387fb2cd.png)</br>
多项式拟合中不只有二次多项式，还可以考虑到三次多项式。如图所示，把预测函数写成如图所示的形式：</br>
![image](https://user-images.githubusercontent.com/130215873/233821352-71136547-9f5f-4144-9c30-c5839a9104a3.png)</br>
接下来采用类似的方法做梯度迭代算法，最后确定各个参数的值。可以发现，随着迭代次数的增加，代价函数没有收敛的趋势。</br>
![image](https://user-images.githubusercontent.com/130215873/233821244-d5f9a5c7-f4d6-4552-9e0b-746a73e89d4f.png)</br>
按照确定的参数，可以把预测函数表示为：</br>
![image](https://user-images.githubusercontent.com/130215873/233821465-a42d28aa-2f9f-4c81-9ed0-15ba0057e69d.png)</br>
可以看到，相对于别的变量，w1的变化对函数值的影响是最大的。所以这里二次函数显然是更适合的选择，而不是三次函数，随着迭代的继续，其他变量的影响会越来越小。
## Scikit-LearScikit-Learn的实验
这个实验比较简单，使用**ikit-Learn**的机器学习相关模型，可以帮助我们更快地完成想要实现的功能。</br> 
![image](https://user-images.githubusercontent.com/130215873/233821714-653f0e85-dc97-4ac5-9b51-5c0cecfd3add.png)</br>
这里用到了scikit-learn来实现LinearRegression，同时用到了一个fit方法。 
接下来我们利用w和b做预测，w和b分别被称为系数和截距。可以使用predict方法来看到预测的结果是多少。</br>
![image](https://user-images.githubusercontent.com/130215873/233821836-9726156f-55d3-4e4c-899b-9c8fef18a69b.png)</br>
对于多维度的问题，Scikit-Learn也能提供帮助。这里用到了Scikit-Learn的方法，非常接近非标准化，也就是未进行缩放特征值的效果。但原来未进行特征值缩放时，需要很长的时间，而使用Scikit-Learn则可以很快地得到结果，如图所示。</br>
![image](https://user-images.githubusercontent.com/130215873/233821981-2891f56b-71e5-441c-9d4f-0a75694fc29a.png)

















