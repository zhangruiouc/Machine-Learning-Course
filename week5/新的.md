# Tensorflow实现
图中所示的是一个Tensorflow网络的实现。网络的实现可以分为三部分：</br>
(1)利用dense创建每一层网络，同时用sequential将每一层网络连接。</br>
(2) 编译model，同时根据需要指定一个loss function。</br>
(3)利用fit来训练模型，epochs是梯度下降的递归次数。</br>
![image](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/bf69977a-5d3c-4d27-a1f9-62cf68fad6af)</br>
# 不同的激活函数
图中所示的是三种不同的activation函数。网络层中的每一层都可以选择一个激活函数。
![image](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/d6f0a383-75aa-4d69-9ee3-7e4dbf0d541b)</br>
三种激活函数分别是：</br>
(1)linear activation function，也可以理解为no activation function。函数值的范围可正可负。</br>
(2)sigmoid。函数值的范围从0到1。</br>
(3)ReLU。函数值大于等于0。</br>
# 如何选择激活函数
激活函数的选择对网络的性能有较大的影响。根据经验，在hidden layer中，往往选择ReLU作为激活函数。在output layer中选择激活函数可以按照如下的方法：</br>
(1)如果我们想解决的是一个binary classification问题，可以选择sigmoid。</br>
(2)如果我们想解决的问题中输出的是一个可正可负的数，选择linear activation。</br>
(3)如果我们想解决的问题的输出都是大于等于0的，那么我们可以选择ReLU。</br>
如图所示是一个简单的网络，在hidden layer中我们选择ReLU，而在output layer中我们选择sigmoid。</br>
![image](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/92611eda-c576-4ae4-86df-9db60ffb28d0)</br>
需要注意的是，我们一般在hidden layer中不使用linear activation。举例说明，如果我们在每一层的hidden layer中都是用linear activation。那么我们的网络最后实现的功能仅仅与最后一层的output layer有关，如果我们的output layer选择sigmoid，那么整个网络所实现的功能仅仅只有logistic regression，前面那么多层的网络都在做无用功。</br>
# multi-class classification
如图所示为binary classification和multi-class classification的例子。在binary classification中输出只有两个分类选择，但是在multi-class classification中可以有多个分类选择。</br>
![image](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/f46ccf37-7491-4e44-8ef9-0b9bec8c3ba1)
# softmax
## softmax原理
如图所示为softmax regression中对各种output的分析。softmax先计算一个中间变量z，再根据这个z计算对应的a。其中a1到a4分别表示输出结果为1到4的概率。可以看到在红框中的aj的定义公式，将每一种可能的output对应的概率相加结果为1。</br>
![image](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/bd16454f-3643-42bc-8a5d-79d299564faf)</br>
如图所示为softmax regression从对损失的定义，如果y=1，那么loss为-loga1，以此类推到an。</br>
图中的函数图像展示了对于aj举例的损失，因为a的计算结果表示一个概率，所以a的大小是从0到1的。如果y=j，那么当aj趋近于1时，损失就比较小；当aj趋近于0时，损失就非常大。在每一个训练的例子中，只能选择一个y。</br>
![image](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/fbb50ed2-f93e-4d46-bacf-c5bb9b0de572)</br>
## softmax输出
如图所示为softmax输出的网络。其中output layer有10个unit，a3是一个10维的向量，每一个分量表示一个概率。可以看到softmax regression与以往的logistic regression最大的不同在于，softmax regression中的输出向量中的每一个分量，可以看成是layer3中计算的从z1到z10的函数，每一个分量的计算都需要从z1到z10的所有值。但是在logistic regression中，activation中的每一个分量其计算仅仅需要z中的一个一个分量，例如a1中的分量计算只需要z1中的一个分量。</br>
![image](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/933b8b19-996c-4ece-9b91-c4b5a3ee7422)</br>
## softmax实现
如图所示为完整的softmax实现，这个实现的过程中改进了原始的softmax方法，使得计算的误差更小。关键的步骤在于编译的阶段中选择loss function中from_logits=True，这个选择使得在loss的计算过程中不再计算a作为中间变量，而是直接将a的表达式代入到loss的计算过程中。</br>
![image](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/e39982b7-d375-4a25-8980-a219243fca00)</br>
如图所示在最后的output layer中，激活函数选择linear，这是因为在改进的softmax实现中，输出的不再是从a1到a10的概率值，而是z1到z10。这样，在predict的环节中，作为预测基础的logits就是从z1到z10。
![image](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/66375867-8909-4974-96cc-d00e8dc5ddff)</br>
# multi-label classification
multi-label classification与multi-class classification是不同的概念。multi-class classification解决的问题是最后的输出结果是多个类别中的一种，比如识别手写数字0到9，最后multi-class classification输出的结果是这个手写的数字是哪一个。但是multi-label classification解决的问题是多标签相关的，比如在一个图片中，可以将不同的东西定义贴上不同的标签，例如car，bus和pedestrian都可以贴上不同的标签，最后的输出结果如图所示是a3，a3的每个分量都可以选择使用sigmoid函数来计算，所以实际上multi-label classification的output layer中的每一个unit都在解决二元分类的分体，即输出的每个分量表示图片中有或者没有car，bus或者pedestrian。</br>
![image](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/c8548aa8-708e-4355-a282-2aaa5571699b)</br>
# 实验
## lab1(multi-class classification)
本次的实验实现multi-class classification。如图所示为实验中生成的四个类别，分别用不同的颜色来标注区分。</br>
![image](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/669cad12-1152-4a0d-8e84-4a75760b6333)</br>
在图中我们实现网络，网络中有两层，分别使用ReLU和linear来作为激活函数，这里使用的代码是改进后的版本，所以在图中的红框部分有from_logits=True，同时选择Adam方法。Adam方法可以在梯度下降的递归过程中选择适当的learning rate，合适的α可以使得梯度下降的过程更快。</br>
![image](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/447e3591-e658-404d-b84d-94d7fd638cc3)</br>
如图所示为分类的结果：</br>
![image](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/24fb84e5-75c8-4c5a-9c50-b8550bb2a8a8)













