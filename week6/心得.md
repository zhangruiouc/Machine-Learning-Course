# 评估模型
在评估模型的过程中，可以将数据集划分为三个部分。分别是：
1. training set
2. cross validation
3. test set
![image](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/1e0d6dd9-8719-4fdf-ab84-379b01d3e740)</br>
如图中所示，将数据集划分为三部分，training set用于训练模型；cross validation用于检验模型，或者可以用来评估模型的准确性如何；test set用于模型的测试，可以理解为这个模型的拓展性如何，即在面对没有在数据集中出现的数据处理的效果怎么样。</br>
![image](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/28103fd7-aeda-481e-a22d-78779d06d519)</br>
如图所示是一个model selection的过程。不同的模型，模型的差别在于拟合时的多项式最高项式，从1到10排序。分别计算他们的Jcv，当d=4时假设此时的Jcv最小，那么选中这个拟合的模型对应的w4和b4。并用这个w4和b4来计算Jtest，Jtest的大小可以作为判断这个模型适用于其他没有出现在training set中的数据的适合程度。</br>
# High bias And High variance
**计算Jtrain和Jcv比较两者的大小，以此判断算法是否高偏差，高方差**</br>
在统计学和机器学习中，高方差（high variance）通常指模型对训练数据的过度拟合，从而导致在新的、未见过的数据上表现较差的情况。在机器学习中，一个常见的目标是在高偏差和高方差之间取得平衡，以达到最佳的泛化性能。</br>
![image](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/ee019084-8f53-4d71-a3d2-ed9860ded637)</br>
如图所示为模型拟合的过程中的三种情况，分别对应：
1. High bias：此时Jtrain很高，Jcv同样很高。
2. Just right：此时Jtrain很低，Jcv同样很低。
3. High variance：此时Jtrain很低，但Jcv很高。
接下来将上述的对High bias和High variance中关于多项式最高次数d的理解来作图，横坐标是degree of polynomial，纵坐标是Jcv和Jtrain的数值：</br>
![image](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/eb52edef-4c92-4ea5-94d0-711b24c4bdb3)</br>
如图所示中的Jtrain随着d的增加而逐渐减小。这是因为当d很小时，拟合的效果不好，也就是under fit的情况，或者说是high bias的情况。此时Jtrain和Jcv的值很高。</br>
随着d的增加，对training set的拟合效果越来越好，甚至出现overfit的情况，即high variance的情况，此时虽然Jtrain很低，但是Jcv的值很高，意味着这个模型的推广性(generalization)并不好。我们希望找到中间的那个Jcv最小的点，意味着此时的模型具有较好地推广性。</br>
# Regulation and bias/variance
![image](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/6c946f5b-ce7b-4d45-83f2-f04909bc6609)</br>
如图所示的cost function中带有regulation term。对λ分析讨论如下：</br>
1. λ非常大：此时因为λ很大，cost function为了达到最小值，会使得w变得很小。如此一来，拟合的模型中多项式前的参数w1到w4就会接近于0，那么拟合出的曲线就近似地变成了一条直线。此时我们遇到了high bias的问题。Jtrain和Jcv都很大。
2. λ非常小，假设极端的情况λ为0。此时regulation term失去了价值，变成了不带regulation term的cost function的情况，此时遇到了high variance的问题，变成了过拟合的模型。Jtrain很小，但是Jcv很大。
3. λ取到了一个恰好的intermediate的数，这样的拟合避免了high variance和high bias的情况，使得Jtrain和Jcv都达到较小的值。
如图所示是在选择regulation parameter λ的例子。我们从λ=0开始尝试，逐次加大λ的值。在这个过程中，选择一个适当的λ，这个λ对应的Jcv最小。图中举得例子是在第五行对应的λ=0.08时的w5和b5最小。将这个w5和b5代入计算Jtest。</br>
![image](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/4fd06748-9f16-47b0-88db-4c98ec38b3e2)</br>
如图中所示展示了Jcv，Jtrain与λ之间的关系图像。</br>
1. 以Jtrain的变化为例，随着λ的增加，cost function为了达到最小值，会使得w变得很小，使得拟合的曲线变成了一条近似直线。此时遇到了high bias的情况，于是Jtrain一直增大。</br>
2. 以Jcv的变化为例，当λ很小时，遇到了过拟合的情况，此时的Jtrain很小，而作为generalization判断的Jcv计算出来的值则很大。</br>
![image](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/56eae5ff-5a66-470b-9c1c-b0dd9b10bc75)</br>
# Establish a baseline level
在计算模型的Jtrain和Jcv的过程中，我们需要一个标准来帮我们判断Jtrain的大小是否合适。Jtrain多大算大，多小算小，有我们设置的baseline决定。比如在音频识别项目中，




