# 评估模型
在评估模型的过程中，可以将数据集划分为三个部分。分别是：
1. training set
2. cross validation
3. test set
![image](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/1e0d6dd9-8719-4fdf-ab84-379b01d3e740)</br>
如图中所示，将数据集划分为三部分，training set用于训练模型；cross validation用于检验模型，或者可以用来评估模型的准确性如何；test set用于模型的测试，可以理解为这个模型的拓展性如何，即在面对没有在数据集中出现的数据处理的效果怎么样。</br>
![image](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/28103fd7-aeda-481e-a22d-78779d06d519)</br>
如图所示是一个model selection的过程。不同的模型，模型的差别在于拟合时的多项式最高项式，从1到10排序。分别计算他们的Jcv，当d=4时假设此时的Jcv最小，那么选中这个拟合的模型对应的w4和b4。并用这个w4和b4来计算Jtest，Jtest的大小可以作为判断这个模型适用于其他没有出现在training set中的数据的适合程度。</br>
# High bias And High variance
**计算Jtrain和Jcv比较两者的大小，以此判断算法是否高偏差，高方差**</br>
在统计学和机器学习中，高方差（high variance）通常指模型对训练数据的过度拟合，从而导致在新的、未见过的数据上表现较差的情况。在机器学习中，一个常见的目标是在高偏差和高方差之间取得平衡，以达到最佳的泛化性能。</br>
![image](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/ee019084-8f53-4d71-a3d2-ed9860ded637)</br>
如图所示为模型拟合的过程中的三种情况，分别对应：
1. High bias：此时Jtrain很高，Jcv同样很高。
2. Just right：此时Jtrain很低，Jcv同样很低。
3. High variance：此时Jtrain很低，但Jcv很高。
接下来将上述的对High bias和High variance中关于多项式最高次数d的理解来作图，横坐标是degree of polynomial，纵坐标是Jcv和Jtrain的数值：</br>
![image](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/eb52edef-4c92-4ea5-94d0-711b24c4bdb3)</br>
如图所示中的Jtrain随着d的增加而逐渐减小。这是因为当d很小时，拟合的效果不好，也就是under fit的情况，或者说是high bias的情况。此时Jtrain和Jcv的值很高。</br>
随着d的增加，对training set的拟合效果越来越好，甚至出现overfit的情况，即high variance的情况，此时虽然Jtrain很低，但是Jcv的值很高，意味着这个模型的推广性(generalization)并不好。我们希望找到中间的那个Jcv最小的点，意味着此时的模型具有较好地推广性。</br>
# Regulation and bias/variance
![image](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/6c946f5b-ce7b-4d45-83f2-f04909bc6609)</br>
如图所示的cost function中带有regulation term。对λ分析讨论如下：</br>
1. λ非常大：此时因为λ很大，cost function为了达到最小值，会使得w变得很小。如此一来，拟合的模型中多项式前的参数w1到w4就会接近于0，那么拟合出的曲线就近似地变成了一条直线。此时我们遇到了high bias的问题。Jtrain和Jcv都很大。
2. λ非常小，假设极端的情况λ为0。此时regulation term失去了价值，变成了不带regulation term的cost function的情况，此时遇到了high variance的问题，变成了过拟合的模型。Jtrain很小，但是Jcv很大。
3. λ取到了一个恰好的intermediate的数，这样的拟合避免了high variance和high bias的情况，使得Jtrain和Jcv都达到较小的值。
如图所示是在选择regulation parameter λ的例子。我们从λ=0开始尝试，逐次加大λ的值。在这个过程中，选择一个适当的λ，这个λ对应的Jcv最小。图中举得例子是在第五行对应的λ=0.08时的w5和b5最小。将这个w5和b5代入计算Jtest。</br>
![image](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/4fd06748-9f16-47b0-88db-4c98ec38b3e2)</br>
如图中所示展示了Jcv，Jtrain与λ之间的关系图像。</br>
1. 以Jtrain的变化为例，随着λ的增加，cost function为了达到最小值，会使得w变得很小，使得拟合的曲线变成了一条近似直线。此时遇到了high bias的情况，于是Jtrain一直增大。</br>
2. 以Jcv的变化为例，当λ很小时，遇到了过拟合的情况，此时的Jtrain很小，而作为generalization判断的Jcv计算出来的值则很大。</br>
![image](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/56eae5ff-5a66-470b-9c1c-b0dd9b10bc75)</br>
# Establish a baseline level
在计算模型的Jtrain和Jcv的过程中，我们需要一个标准来帮我们判断Jtrain的大小是否合适。Jtrain多大算大，多小算小，有我们设置的baseline performance决定。比如在音频识别项目中，人类的识别效果错误率尚且有百分十左右，那么如果我们的模型能达到Jtrain百分十多一点的效果，也是非常出色的。</br>
通过比较Jtrain和baseline performance，Jtrain和Jcv之间的大小可以判断我们的模型是否存在high bias或者high variance的情况。</br>
1. baseline performance与Jtrain之间的差距较小，但是Jtrain与Jcv之间的差距较大，可能存在high variance的情况。
2. baseline performance与Jtrain之间的差距较大，Jtrain与Jcv之间的差距较小，可能存在high bias的情况。
3. baseline performance与Jtrain之间的差距较大，Jtrain与Jcv之间的差距同样较大，可能存在high bias和high variance同时存在的情况。
![image](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/df8828f1-c18a-4a9d-a5ea-3b7f06731ed4)</br>
# Learning Curve
如图所示为high bias的情况。如果我们的学learning algorithm遇到了high bias的情况，那么增加我们的training set带来的帮助非常有限。随着训练集的增加，我们的拟合效果并不一定会变得更好，因为拟合的函数或者说模型本身存在一定的问题。</br>
1. 在training set的数据较少时，Jtrain可以做到较小，但Jcv依然较大。
2. 在training set的数据较多时，Jtrain不可避免的变大，而Jcv可以减小。但它们最终都趋于平缓。
![image](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/87ecd7e0-8a05-4275-abeb-4e8581a630d0)</br>
如图所示为high variance的情况。如果我们的learning algorithm遇到了high variance的情况，那么增大我们的训练集是很可能带来较大的帮助的。</br>
![image](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/e46e4c2d-6b6d-4e1c-89cc-e1d7bb4a9c9f)</br>
# Debugging a learning algorithm
如图所示为在做房屋价格预测时的线性回归模型可能遇到的问题，以及问题对应的解决方法。线性回归模型中引入了regulation term。</br>
![image](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/5e9cfde2-58be-4e28-8fd8-7e45d031e6e1)</br>
1. 以解决high bias的一种方法为例。我们可以尝试添加更高项的多项式来拟合，这样的曲线可以更好地拟合training set的数据，以此来解决high bias的问题。
2. 以解决high variance的一种方法为例。我们可以尝试增大我们的数据集，这样我们的模型就不会仅仅局限于拟合初始的数据集中的数据，也会关心后续添加的数据，以此来解决high variance的问题。
# Neural Networks and bias variance
在实际的问题中，我们很难同时兼顾到Jtrain和Jcv的大小。于是，我们选择在一次的变化中，只关注Jtrain或者Jcv。如图所示的流程图中，如果我们的learning algorithm在training set上可以或者不错的Jtrain，我们就继续检验learning algorithm在cross validation上的表现如何，即Jcv的大小。图中展示了不断调整的过程，如果在training set上的表现不佳，可以尝试用更大的网络；如果在cross validation上的表现不佳，可以尝试增大我们的数据集。</br>
![image](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/3dd3f0f7-d4a9-40d1-a179-0e4955f41360)</br>
事实证明，更大的网络往往比更小的网络表现得更好，至少也能做到旗鼓相当的效果，前提是选择一个正确的regulation term中的λ。更大的网络需要更长的训练时间。</br>
![image](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/303b04c0-9cb2-4563-ab94-3449b8edd6e6)






