# 决定下一步做什么
以下的这些诊断法则可以帮助我们判断哪些方法可能有助于改进学习算法的效果。
1. 获得更多的训练样本——解决高方差
2. 尝试减少特征的数量——解决高方差
3. 尝试获得更多的特征——解决高偏差
4. 尝试增加多项式特征——解决高偏差
5. 尝试减少正则化程度λ——解决高偏差
6. 尝试增加正则化程度λ——解决高方差
神经网络的方差和偏差如图所示：
![](../images/c5cd6fa2eb9aea9c581b2d78f2f4ea57.png)

使用较小的神经网络，类似于参数较少的情况，容易导致高偏差和欠拟合，但计算代价较小使用较大的神经网络，类似于参数较多的情况，容易导致高方差和过拟合，虽然计算代价比较大，但是可以通过正则化手段来调整而更加适应数据。
	
通常我们认为选择较大的神经网络并采用正则化处理会比采用较小的神经网络效果要好。
	
对于神经网络中的隐藏层的层数的选择，通常从一层开始逐渐增加层数，为了更好地作选择，可以把数据分为训练集、交叉验证集和测试集，针对不同隐藏层层数的神经网络训练神经网络，
然后选择交叉验证集代价最小的神经网络。

# 垃圾邮件分类的例子
	
以一个垃圾邮件分类器算法为例进行讨论。为了解决这样一个问题，我们首先要做的决定是如何选择并表达特征向量x。我们可以选择一个由100个最常出现在垃圾邮件中的词所构成的列表，根据这些词是否有在邮件中出现，来获得我们的特征向量（出现为1，不出现为0），尺寸为100×1。

为了构建这个分类器算法，我们可以做很多事，例如：
1. 收集更多的数据，让我们有更多的垃圾邮件和非垃圾邮件的样本
2. 基于邮件的路由信息开发一系列复杂的特征
3. 基于邮件的正文信息开发一系列复杂的特征，包括考虑截词的处理
4. 为探测刻意的拼写错误（把**watch** 写成**w4tch**）开发复杂的算法
    
我们将在随后的课程中讲误差分析，误差分析可以帮助我们用一个更加系统性的方法，从不同的方法中选取合适的那一个。

### 误差分析
	
构建一个学习算法的推荐方法为：
	
1. 从一个简单的能快速实现的算法开始，实现该算法并用交叉验证集数据测试这个算法
2.绘制学习曲线，决定是增加更多数据，或者添加更多特征，还是其他选择
3.进行误差分析：人工检查交叉验证集中我们算法中产生预测误差的样本，看看这些样本是否有某种系统化的趋势

以我们的垃圾邮件过滤器为例，误差分析要做的既是检验交叉验证集中我们的算法产生错误预测的所有邮件，看：是否能将这些邮件按照类分组。例如医药品垃圾邮件，仿冒品垃圾邮件或者密码窃取邮件等。然后看分类器对哪一组邮件的预测误差最大，并着手优化。
	
思考怎样能改进分类器。例如，发现是否缺少某些特征，记下这些特征出现的次数。
	
例如记录下错误拼写出现了多少次，异常的邮件路由情况出现了多少次等等，然后从出现次数最多的情况开始着手优化。
	
在模型比较时，用数值来判断哪一个模型更好更有效，通常我们是看交叉验证集的误差。
	
当研究一个新的机器学习问题时，实现一个较为简单快速、即便不是那么完美的算法有利于我们决定下一步该做什么，看看算法造成的错误，通过误差分析来看看他犯了什么错。

# 类偏斜的误差度量

偏斜类（skewed classes）表现为我们的训练集中有非常多的同一种类的样本，只有很少或没有其他类的样本。
	
例如我们希望用算法来预测癌症是否是恶性的，在我们的训练集中，只有0.5%的实例是恶性肿瘤。假设我们编写一个非学习而来的算法，在所有情况下都预测肿瘤是良性的，那么误差只有0.5%。然而我们通过训练而得到的神经网络算法却有1%的误差。这时，误差的大小是不能视为评判算法效果的依据的。
	
**查准率**（**Precision**）和**查全率**（**Recall**） 我们将算法预测的结果分成四种情况：

	|            |              | **预测值**   |             |
| ---------- | ------------ | ------------ | ----------- |
|            |              | **Positive** | **Negtive** |
| **实际值** | **Positive** | **TP**       | **FN**      |
|            | **Negtive**  | **FP**       | **TN**      |

pression=**TP/(TP+FP)**。意味着在所有我们预测有恶性肿瘤的病人中，实际上有恶性肿瘤的病人的百分比，越高越好。
	
recall=**TP/(TP+FN)**。意味着在所有实际上有恶性肿瘤的病人中，成功预测有恶性肿瘤的病人的百分比，越高越好。

# 查准率和召回率之间的权衡

![](../images/ad00c2043ab31f32deb2a1eb456b7246.png)

查准率 **(Precision)=TP/(TP+FP)**
例，在所有我们预测有恶性肿瘤的病人中，实际上有恶性肿瘤的病人的百分比，越高越好。

查全率 **(Recall)=TP/(TP+FN)**
在所有实际上有恶性肿瘤的病人中，成功预测有恶性肿瘤的病人的百分比，越高越好。
	
如果我们希望只在非常确信的情况下预测为真（肿瘤为恶性），即我们希望更高的查准率，我们可以使用比0.5更大的阀值，如0.7，0.9。这样做我们会减少错误预测病人为恶性肿瘤的情况，同时却会增加未能成功预测肿瘤为恶性的情况。
	
如果我们希望提高查全率，尽可能地让所有有可能是恶性肿瘤的病人都得到进一步地检查、诊断，我们可以使用比0.5更小的阀值，如0.3。
	
我们可以将不同阀值情况下，查全率与查准率的关系绘制成图表，曲线的形状根据数据的不同而不同：

![](../images/84067e23f2ab0423679379afc6ed6caf.png)

我们希望有一个帮助我们选择这个阀值的方法。一种方法是计算**F1 值**（**F1 Score**），其计算公式为：

![image](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/0c28a0ce-a8c5-4259-aea7-6c474870d419)

我们选择使得**F1**值最高的阀值。

# 机器学习的数据

![](../images/1a7c575dc1b606b8e6e4de71a14dc005.png)

在这样的句子中：早餐我吃了__个鸡蛋(**to**,**two**,**too**)，在这个例子中，“早餐我吃了2个鸡蛋”，这是一个易混淆的单词的例子。于是他们把诸如这样的机器学习问题，当做一类监督学习问题，并尝试将其分类，什么样的词，在一个英文句子特定的位置，才是合适的。研究人员使用了几种不同的学习算法，同时改变了训练数据集的大小，并尝试将这些学习算法用于不同大小的训练数据集中，他们得到的结果如下。

![](../images/befe860fd4b1aef2f6eebf617baf5877.jpg)

这些趋势非常明显，首先大部分算法，都具有相似的性能，其次，随着训练数据集的增大，这些算法的性能也都对应地增强了。这些结果表明，许多不同的学习算法有时倾向于表现出非常相似的表现，这还取决于一些细节，但是真正能提高性能的，是你能够给一个算法大量的训练数据。
	
那么让我们来看一看，大量的数据是有帮助的情况。假设特征值有足够的信息来预测y值，假设我们使用一种需要大量参数的学习算法，比如有很多特征的逻辑回归或线性回归，或者用带有许多隐藏单元的神经网络，那又是另外一种带有很多参数的学习算法，它们有很多参数，这些参数可以拟合非常复杂的函数。将把这些算法想象成低偏差算法，因为我们能够拟合非常复杂的函数，而且因为我们有非常强大的学习算法，这些学习算法能够拟合非常复杂的函数。用这些数据运行这些算法能很好地拟合训练集，因此，训练误差就会很低了。
	
现在假设我们使用了非常非常大的训练集，在这种情况下，尽管我们希望有很多参数，但是如果训练集比参数的数量还大，甚至是更多，那么这些算法就不太可能会过拟合。
	
另一种考虑这个问题的角度是为了有一个高性能的学习算法，我们希望它不要有高的偏差和方差。
	
因此偏差问题，我么将通过确保有一个具有很多参数的学习算法来解决，以便我们能够得到一个较低偏差的算法，并且通过用非常大的训练集来保证。

![](../images/05a3c884505e08028d37a04472d0964a.png)

我们在此没有方差问题，并且通过将这两个值放在一起，我们最终可以得到一个低误差和低方差的学习算法。这使得我们能够很好地测试测试数据集。
