### 在线学习

在线学习特别适合有着连续的数据流的网站和手机上的应用。如果我们有一个由连续的用户流引发的连续的数据流，进入我们的的网站，我们能做的是使用一个在线学习机制，从数据流中学习用户的偏好，然后使用这些信息来优化一些关于网站的决策。

接下来以提供运输服务的快递公司的在线订单服务为例，介绍一个与在线学习有关的例子。

假定我们有一个提供运输服务的公司，用户们来向我们询问把包裹从**A**地运到**B**地的服务，同时假定我们有一个网站，让用户们可多次登陆，然后他们在网站上登记信息，包括他们想从哪里寄出包裹，以及包裹要寄到哪里去，也就是出发地与目的地，然后网站开出运输包裹的的服务价格。比如，我会收取50元来运输你的包裹。然后根据我们开给用户的这个价格，用户有时会接受这个运输服务，那么这就是个正样本。如果用户拒绝购买我们的运输服务，这就是一个负样例。

我们可以设计一个在线学习算法来帮助我们优化给用户开出的价格。在线学习算法指的是对数据流而非离线的静态数据集的学习。许多在线网站都有持续不断的用户流，对于每一个用户，网站希望能在不将数据存储到数据库中，也能顺利地进行算法学习。

假使我们正在经营一家物流公司，每当一个用户询问从地点**A**至地点**B**的快递费用时，我们给用户一个报价，该用户可能选择接受（$y=1$）或不接受（$y=0$）。

现在，我们希望构建一个模型，来预测用户接受报价使用我们的物流服务的可能性。因此**报价**
是我们的一个特征，其他特征包括距离，起始地点，目标地点以及特定的用户数据。模型的输出是:$p(y=1)$。

在线学习的算法与随机梯度下降算法有些类似，我们对单一的实例进行学习，而不是对一个提前定义的训练集进行循环。

![image](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/546d35ec-d78f-4662-b2f7-a06ec9cd15cf)

每一次对单个例子的学习，都可以更新一次学习的参数$\theta$。

一旦对一个数据的学习完成了，我们便可以丢弃该数据，不需要再存储它了。这种方式的好处在于，我们的算法可以很好的适应用户的倾向性，算法可以针对用户的当前行为不断地更新模型以适应该用户。

每次交互事件并不只产生一个数据集，例如，我们一次给用户提供3个物流选项，用户选择2项，我们实际上可以获得3个新的训练实例，因而我们的算法可以一次从3个实例中学习并更新模型。

这些问题中的任何一个都可以被归类到标准的，拥有一个固定的样本集的机器学习问题中。但是在这些问题里，大公司的网站会获取如此多的数据，没有必要来保存一个固定的数据集，取而代之的是可以使用一个在线学习算法来连续的学习，从这些用户不断产生的数据中来学习。这就是在线学习机制。

### 映射化简和数据并行

映射化简和数据并行对于大规模机器学习问题而言是非常重要的概念。以批量梯度下降算法为例，如果我们用批量梯度下降算法来求解大规模数据集的最优解，我们需要对整个训练集进行循环，计算偏导数和代价函数的结果，再求和，计算代价非常大。如果我们能够将我们的数据集分配给不多台计算机，让每一台计算机处理数据集的一个子集，然后我们将计所的结果汇总在求和，就可以大大减轻一台机器的计算压力。这样的方法叫做映射简化。

具体而言，如果任何学习算法能够表达为：

对训练集的函数的求和，那么便能将这个任务分配给多台计算机（或者同一台计算机的不同CPU 核心），以达到加速处理的目的。

例如，我们有400个训练实例，我们可以将批量梯度下降的求和任务分配给4台计算机进行处理：

![image](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/46471ddc-e304-40b0-a9f4-6e50c2073682)

映射简化的应用还包括将一个任务分配给一台主机的CPU上的多个核心，让各核心并行处理数据。这种方法相对于将任务分配给多个主机的映射来说，减少了网络的延迟。

![image](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/d6c7add1-926a-42c6-9651-53aaf8ec49d1)

很多高级的线性代数函数库已经能够利用多核**CPU**的多个核心来并行地处理矩阵运算，这也是算法的向量化实现如此重要的缘故（比调用循环快）。

映射化简和数据并行的一个应用就包括接下来涉及的**图片文字识别(Application Example: Photo OCR)**。

### 问题描述和流程图

图像文字识别应用所作的事是，从一张给定的图片中识别文字。这比从一份扫描文档中识别文字要复杂的多。

![095e4712376c26ff7ffa260125760140](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/258f9d2b-1d6e-4c8e-aa03-68588af2647b)

为了完成这样的工作，需要采取如下步骤：

1. 文字侦测（**Text detection**）——将图片上的文字与其他环境对象分离开来

2. 字符切分（**Character segmentation**）——将文字分割成一个个单一的字符

3. 字符分类（**Character classification**）——确定每一个字符是什么

我们可以用任务流程图来表达这个问题，每一项任务可以由一个单独的团队来负责解决：

![610fffb413d8d577882d6345c166a9fb](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/0d6ed724-8110-4f22-8b6e-3beb99d0d4f1)

### 滑动窗口

滑动窗口是一项用来从图像中抽取对象的技术。如果我们需要在一张图片中识别行人，首先要做的是用许多固定尺寸的图片来训练一个能够准确识别行人的模型。然后我们用之前训练识别行人的模型来处理如图所示裁剪的图片内容，让模型判断如所示的**绿色方框内**是否为行人，然后在图片上滑动剪裁区域重新进行剪裁，将新剪裁的切片也交给模型进行判断，如此循环直至将图片全部检测完。

![1e00d03719e20eeaf1f414f99d7f4109](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/1059b80d-1ad3-46c4-b867-8a1b81d8c90b)

滑动窗口技术也被用于文字识别。首先训练模型能够区分字符与非字符，然后，运用滑动窗口技术识别字符，一旦完成了字符的识别，我们将识别出的区域进行一些扩展。比如模型在识别的框内认为有字符出现，那么将框外一部分的像素也包括进来，认为包括新添加的像素在内的框内都是有字符的。接着将重叠的区域进行合并，然后我们以宽高比作为过滤条件，过滤掉高度比宽度更大的区域（认为单词的长度通常比高度要大）。下图中绿色的区域是经过这些步骤后被认为是文字的区域，而红色的区域是因为长度小于宽度而被忽略掉不是文字的区域。

![bc48a4b0c7257591643eb50f2bf46db6](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/f1d94d3d-7303-4182-b4ed-5146cb0d727c)

以上便是文字侦测（**Text detection**）阶段。

下一步是字符切分（**Character segmentation**）部分。我们要训练一个模型来完成将文字分割成一个个字符的任务，需要的训练集由单个字符的图片和两个相连字符之间的图片来训练模型。

![0a930f2083bbeb85837f018b74fd0a02](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/91434eb1-ef4e-4d4e-8752-e16576df60be)

![0bde4f379c8a46c2074336ecce1a955f](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/f26ac3f5-9022-4fe4-84ce-03dfb29c1794)

模型训练的过程中，认为需要分割字符的是正样本，不需要分割字符的是负样本。模型训练完后，我们仍然是使用滑动窗口技术来进行字符识别。

最后一个阶段是字符分类阶段，可以利用神经网络、支持向量机或者逻辑回归算法训练一个分类器。

### 获取大量数据和人工数据

在我们的模型是低方差的这个前提下，获得更多的数据用于训练模型，是能够有更好的效果的。有时，已知的数据是有限的，那么我们有时就需要人工地创造一些新的数据。

以我们的文字识别应用为例，我们可以在字体网站下载各种字体，然后利用这些不同的字体配上各种不同的随机背景图片创造出一些用于训练的实例，这让我们能够获得一个无限大的训练集。这是从零开始创造实例。

![image](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/4e02072d-1f16-4361-a0a3-111c40bf2f5c)

另一种方法是，利用已有的数据，然后对其进行修改，例如将已有的字符图片进行一些扭曲、旋转、模糊处理。只要我们认为实际数据有可能和经过这样处理后的数据类似，我们便可以用这样的方法来创造大量的数据。

![image](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/725beefa-cb2b-464c-9ae0-6da8fa75058a)

有关获得更多数据的几种方法：

  1. 人工数据合成

  2. 手动收集、标记数据

  3. 众包

### 上限分析：流水线模型的哪个部分值得深入继续

在机器学习的应用中，我们通常需要通过几个步骤才能进行最终的预测，我们如何能够知道哪一部分最值得我们花时间和精力去改善呢？这个问题可以通过上限分析来回答。

回到我们的文字识别应用中，我们的流程图如下：

![55d41ee748680a62e755d6aa5b95b53c](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/1a91c5dc-f722-43ef-8459-d7fb17fce06d)

流程图中每一部分的输出都是下一部分的输入，上限分析中，我们选取一部分，手工提供100%正确的输出结果，然后看应用的整体效果提升了多少。

假使我们的例子中总体效果为72%的正确率。如果我们令文字侦测部分（**Text detection**）输出的结果100%正确，发现系统的总体效果从72%提高到了89%。这意味着我们很可能会希望投入时间精力来提高我们的文字侦测部分。

接着我们手动选择数据，让字符切分（**Character segmentation**）输出的结果100%正确，发现系统的总体效果只提升了1%，这意味着，我们的字符切分部分可能已经足够好了。

最后我们手工选择数据，让字符分类（**Character classification**）输出的结果100%正确，系统的总体效果又提升了10%，这意味着我们可能也会应该投入更多的时间和精力来提高应用的总体表现。

![f1ecee10884098f98032648da08f8937](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/21d1c24e-5d11-4e68-bab8-24fb624f4e7e)

同样的上限分析方法可以适用于**Face recognition from images**这样的项目。
该项目的流水线处理过程如图所示，包括了**Preprocess**，**Face detection**，**Logistic regression**这样的模块。其中，**Face detection**还包括**Eyes segmentation**，**Nose segmentation**以及**Mouth segmentation**这三个部分。采取上限分析的方法，我们可以依次地手动选择上述每个模块的100%正确输出，来查看每个模块百分百正确后对项目的整体影响，以此来判断选择继续深入修改哪一个模块可以使得我们的输出结果更加理想。

如图所示可以看出，继续深入**Face detection**，**Eyes segmentation**和**Logistic regression**这样的模块是更有性价比的选择。而继续深入**Preprocess**这样的模块带来的提升是非常有限的。

![image](https://github.com/zhangruiouc/Machine-Learning-Course/assets/130215873/b0babd97-7e46-4318-b4f8-513cc7d2b10a)

